{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15f77a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nPrior: initiallit, this prob is 1/10,000 becuase we don'y have any other info other than the fact that 1 out of 10000 patients is sick\\nEvent: new information comes to light, in ths case the patient took a test and tested positive\\nPosterior: after coming out positive, we recalc. the prob that the patient is sick, and that comes out to be .0098. This is the posterior\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# purely probabilistic, prediction between 0 and 1\n",
    "# 3 stages, the prior (initial probablility), the event (something that occurs) and the posterior ( the final probability that we caluclate usig the prior prob and the event)\n",
    "\n",
    "# as an example, we have a medical example with some numbers:\n",
    "\"\"\"\n",
    "Prior: initially, this prob is 1/10,000 becuase we don'y have any other info other than the fact that 1 out of 10000 patients is sick\n",
    "Event: new information comes to light, in ths case the patient took a test and tested positive\n",
    "Posterior: after coming out positive, we recalc. the prob that the patient is sick, and that comes out to be .0098. This is the posterior\n",
    "\"\"\"\n",
    "\n",
    "# this theorum is the most important building blocks of prob and of ML. It is actually so important that several fields are named after it like bayesian learning, bayesian stats, bayesian analysis\n",
    "# simply, it predicts a label out of a set of features. It returns the answer in the from of a prob. which is calculated using bayes theorum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdc67ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nIn action, we will do a spam or ham email example\\n\\nWe find the prior, probability that any email is spam (rough estimate)\\nin this exampe it is 0.2\\n\\nthe event would be a specific word the email contains\\n\\nWe find the posterior: prob that an email is spam, knowing that it contains a particular word \\nin this case it is 0.75 chance of it being spam if it contains the word 'lottery'\\n\\n\\nThe math that happened was we turned ratios into a probability\\n\\nThe naive bayes revolves around proababilties, so divin into probability math alone would be great to know if you want to nerd out.\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "In action, we will do a spam or ham email example\n",
    "\n",
    "We find the prior, probability that any email is spam (rough estimate)\n",
    "in this exampe it is 0.2\n",
    "\n",
    "the event would be a specific word the email contains\n",
    "\n",
    "We find the posterior: prob that an email is spam, knowing that it contains a particular word \n",
    "in this case it is 0.75 chance of it being spam if it contains the word 'lottery'\n",
    "\n",
    "\n",
    "The math that happened was we turned ratios into a probability\n",
    "\n",
    "The naive bayes revolves around proababilties, so divin into probability math alone would be great to know if you want to nerd out.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a23471b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "emails = pandas.read_csv('emails.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9721f0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we turn the text string into a list of words\n",
    "def process_email(text):\n",
    "    text = text.lower()\n",
    "    return list(set(text.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14544805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column\n",
    "emails['words'] = emails['text'].apply(process_email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdf3309e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2388268156424581"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alright lets find the priors. we calc the num of emails that are spam and divide by total number of emails\n",
    "sum(emails['spam']) / len(emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebea7506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alright lets find the posterior with bayes theorum\n",
    "model = {}\n",
    "\n",
    "for index, email in emails.iterrows():\n",
    "    for word in email['words']:\n",
    "        if word not in model:\n",
    "            model[word] = {'spam': 1, 'ham': 1}\n",
    "        if word in model:\n",
    "            if email['spam']:\n",
    "                model[word]['spam'] += 1\n",
    "            else:\n",
    "                model[word]['ham'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ee09d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spam': 9, 'ham': 1}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['lottery']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e48d5303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spam': 39, 'ham': 42}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['sale']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9c32cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# okay so we have our posterior now\n",
    "# we will now implement the naive bayes algo, the input is the email and goes through all words in the email, and for each word it calcs the probs that a spam email contains it and that a ham email contains it.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def predict_naive_bayes(email):\n",
    "    total = len(emails)\n",
    "    num_spam = sum(emails['spam'])\n",
    "    num_ham = total - num_spam\n",
    "    email = email.lower()\n",
    "    words = set(email.split())\n",
    "    spams = [1.0]\n",
    "    hams = [1.0]\n",
    "    for word in words:\n",
    "        if word in model:\n",
    "            spams.append(model[word]['spam']/num_spam*total)\n",
    "            hams.append(model[word]['ham']/num_ham*total)\n",
    "    prod_spams = int(np.prod(spams) * num_spam)\n",
    "    prod_hams = int(np.prod(hams) * num_ham)\n",
    "    return prod_spams / (prod_spams + prod_hams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf833fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12554358867164467"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_naive_bayes('Hi mom how are you')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6879c464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.964603508395963e-05"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_naive_bayes('meet me at the lobby of the hotel at nine am')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dea4ca26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999973472265966"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_naive_bayes('buy cheap lottery easy money now')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b082251b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2388268156424581"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_naive_bayes('asdfgh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba03d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nNOTE:\\n\\nThis was a quick implementation of the naive Bayes algorithm. But for larger datasets, and larger\\nemails, we should use a package. Packages like Scikit-Learn offer great implementations of the\\nnaive Bayes algorithm, with many parameters to play with. Explore this and other packages, and\\nuse the naive Bayes algorithm on all types of datasets!\\n\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "NOTE:\n",
    "\n",
    "This was a quick implementation of the naive Bayes algorithm. But for larger datasets, and larger\n",
    "emails, we should use a package. Packages like Scikit-Learn offer great implementations of the\n",
    "naive Bayes algorithm, with many parameters to play with. Explore this and other packages, and\n",
    "use the naive Bayes algorithm on all types of datasets!\n",
    "\n",
    "SUMMARY:\n",
    "\n",
    "-Bayes theorem is a technique widely used in probability, statistics, and machine learning.\n",
    "-Bayes theorem consists of calculating a posterior probability, based on a prior probability\n",
    "and an event.\n",
    "-The prior probability is a basic calculation of a probability, given very little information.\n",
    "-Bayes theorem uses the event to make a much better estimate of the probability in\n",
    "question.\n",
    "-The naive Bayes algorithm is used when one wants to combine a prior probability\n",
    "together with several events.\n",
    "-The word naive comes from the fact that we are making a naive assumption, namely, that\n",
    "the events in question are all independent.\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Grokking ML)",
   "language": "python",
   "name": "grokking-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
